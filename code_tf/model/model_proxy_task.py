
from keras.models import Model
from keras.layers import Input, concatenate, Conv2D, Conv3D, Reshape, Dropout, MaxPool2D,UpSampling2D, ZeroPadding2D, Activation, Permute
from keras import metrics
import keras

class ModelInit():  

        def __init__(self, params):
                super().__init__()
                self.params = params
        
        def build_attention_gate(self, g, s, num_filters):
            Wg = Conv2D(num_filters, 1, strides = (2,2), padding="valid")(g)
            Ws = Conv2D(num_filters, 1, padding="same")(s)

            out = Activation("relu")(Wg + Ws)
            out = Conv2D(1, 1, padding="same")(out)
            out = Activation("sigmoid")(out)
            out = UpSampling2D()(out)
            return out * g
        
        def build_model(self):

                """The deep learning architecture gets defined here"""
                # Input Optical Properties
                inOP_beg = Input(shape=(self.params['xX'],self.params['yY'],2))
                ## Input Multi-Dimensional Fluorescence
                inFL_beg = Input(shape=(self.params['nF'], self.params['xX'], self.params['yY'], 1))

                #3D CNN for all layers

                ## Optical Properties Branch ##
                inOP = Conv2D(filters=self.params['nFilters2D']//2, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], 
                        padding='same', activation=self.params['activation'], data_format="channels_last")(inOP_beg)
                # inOP = Dropout(0.75)(inOP)

                inOP = Conv2D(filters=int(self.params['nFilters2D']/2), kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], 
                        padding='same', activation=self.params['activation'], data_format="channels_last")(inOP)
                # inOP = Dropout(0.75)(inOP)
                
                inOP = Conv2D(filters=int(self.params['nFilters2D']/2), kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], 
                        padding='same', activation=self.params['activation'], data_format="channels_last")(inOP)
                # inOP = Dropout(0.75)(inOP)  

                ## Fluorescence Input Branch ##
                input_shape = inFL_beg.shape
                inFL = Conv3D(filters=self.params['nFilters3D']//2, kernel_size=self.params['kernelConv3D'], strides=self.params['strideConv3D'], 
                        padding='same', activation=self.params['activation'], input_shape=input_shape[1:], data_format="channels_last")(inFL_beg)
                # inFL = Dropout(0.75)(inFL)

                inFL = Conv3D(filters=int(self.params['nFilters3D']/2), kernel_size=self.params['kernelConv3D'], strides=self.params['strideConv3D'], 
                        padding='same', activation=self.params['activation'], data_format="channels_last")(inFL)
                # inFL = Dropout(0.75)(inFL)
                inFL = Conv3D(filters=int(self.params['nFilters3D']/2), kernel_size=self.params['kernelConv3D'], strides=self.params['strideConv3D'], 
                        padding='same', activation=self.params['activation'], data_format="channels_last")(inFL)
                # inFL = Dropout(0.75)(inFL)

                ## Concatenate Branch ##
                inFL = Permute((2, 3, 1, 4))(inFL)
                inFL = Reshape((inFL.shape[1], inFL.shape[2], inFL.shape[3] * inFL.shape[4]))(inFL)
                concat = concatenate([inOP,inFL],axis=-1)

                Max_Pool_1 = MaxPool2D()(concat)

                Conv_1 = Conv2D(filters=256, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Max_Pool_1)
                Conv_1 = Conv2D(filters=256, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_1)
                
                Max_Pool_2 = MaxPool2D()(Conv_1)

                Conv_2 = Conv2D(filters=512, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Max_Pool_2)
                Conv_2 = Conv2D(filters=512, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_2)

                Max_Pool_3 = MaxPool2D()(Conv_2)

                Conv_3 = Conv2D(filters=1024, kernel_size=(self.params['kernelConv2D']), strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Max_Pool_3)
                Conv_3 = Conv2D(filters=1024, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_3)

                #decoder 

                #adjust size of Conv_2
                long_path_1 = Conv_2[:,0:Conv_2.shape[1] - 1, 0:Conv_2.shape[2] - 1, :]
                attention_1 = self.build_attention_gate(long_path_1, Conv_3, 512)

                Up_conv_1 = UpSampling2D()(Conv_3)

                
                Up_conv_1 = Conv2D(filters=512, kernel_size = (2,2), strides=(1,1), padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Up_conv_1)

                #attention block 
                concat_1 = concatenate([Up_conv_1,attention_1],axis=-1)

                Conv_4 = Conv2D(filters=512, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(concat_1)

                Conv_4 = Conv2D(filters=512, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                                activation=self.params['activation'], data_format="channels_last")(Conv_4)
                
                long_path_2 = Conv_1
                Conv_4_zero_pad = ZeroPadding2D(padding = ((1,0), (1,0)))(Conv_4)

                attention_2 = self.build_attention_gate(long_path_2, Conv_4_zero_pad, 256)

                Up_conv_2 = UpSampling2D()(Conv_4)

                Up_conv_2 = Conv2D(filters=256, kernel_size = (2,2), strides=(1,1), padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Up_conv_2)

                Up_conv_2 = ZeroPadding2D()(Up_conv_2)

                concat_2 = concatenate([Up_conv_2,attention_2],axis=-1)

                Conv_5 = Conv2D(filters=256, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(concat_2)
                Conv_5 = Conv2D(filters=256, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_5)
                
                long_path_3 = ZeroPadding2D(padding = ((1,0), (1,0)))(concat)
                Conv_5_zero_pad = ZeroPadding2D(padding = ((1,0), (1,0)))(Conv_5)

                attention_3 = self.build_attention_gate(long_path_3, Conv_5_zero_pad, 128)

                Up_conv_3 = UpSampling2D()(Conv_5)
                Up_conv_3 = Conv2D(filters=128, kernel_size = (2,2), strides=(1,1), padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Up_conv_3)
                                
                Up_conv_3 = ZeroPadding2D(padding = ((1,0), (1,0)))(Up_conv_3)

                attention_3 = attention_3[:,0:attention_3.shape[1] - 1, 0:attention_3.shape[2] - 1, :]
                concat_3 = concatenate([Up_conv_3,attention_3],axis=-1)  

                Conv_6 = Conv2D(filters=128, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(concat_3)

                ## Quantitative Fluorescence Output Branch ##
                outQF = Conv2D(filters=64, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_6)

                outQF = Conv2D(filters=32, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(outQF) #outQF
                
                outQF = Conv2D(filters=1, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                                data_format="channels_last", name='outQF')(outQF)

                ## Depth Fluorescence Output Branch ##
                #first DF layer 
                outDF = Conv2D(filters=64, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(Conv_6)

                outDF = Conv2D(filters=32, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        activation=self.params['activation'], data_format="channels_last")(outDF)
                
                outDF = Conv2D(filters=1, kernel_size=self.params['kernelConv2D'], strides=self.params['strideConv2D'], padding='same', 
                        data_format="channels_last", name='outDF')(outDF)
                
                ## Reflectance Output Branch (proxy task)
                outReflect = Conv2D(
                    filters=64,
                    kernel_size=self.params['kernelConv2D'],
                    strides=self.params['strideConv2D'],
                    padding='same',
                    activation=self.params['activation'],
                    data_format="channels_last"
                )(Conv_6)

                outReflect = Conv2D(
                    filters=32,
                    kernel_size=self.params['kernelConv2D'],
                    strides=self.params['strideConv2D'],
                    padding='same',
                    activation=self.params['activation'],
                    data_format="channels_last"
                )(outReflect)

                # Final layer: output 6 reflectance channels
                outReflect = Conv2D(
                    filters=6,  # Number of reflectance images per input
                    kernel_size=1,
                    strides=1,
                    padding='same',
                    activation=None,  # Or 'linear'
                    data_format="channels_last",
                    name='outReflect'
                )(outReflect)

                ## Defining and compiling the model ##

                self.model = Model(inputs=[inOP_beg, inFL_beg], outputs=[outQF, outDF, outReflect])

                self.model.compile(
                    loss={'outQF': 'mae', 'outDF': 'mae', 'outReflect': 'mae'},
                    optimizer=getattr(keras.optimizers, self.params['optimizer'])(learning_rate=self.params['learningRate']),
                    metrics={
                        'outQF': metrics.MeanAbsoluteError(name='mae_qf'),
                        'outDF': metrics.MeanAbsoluteError(name='mae_df'),
                        'outReflect': metrics.MeanAbsoluteError(name='mae_reflect')
                    },
                    loss_weights={'outQF': 1.0, 'outDF': 1.0, 'outReflect': 1.0}
                )
                
                self.model.summary()

                return None
        
        def load_model(self, model_path):
            self.model = keras.models.load_model(model_path)
            return None